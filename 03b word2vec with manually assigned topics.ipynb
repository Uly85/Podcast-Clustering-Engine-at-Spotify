{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5721a2e3",
   "metadata": {},
   "source": [
    "# Import Packages and Create Spark Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8af0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re as re\n",
    "import databricks.koalas as ks\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim, operator\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"SpotifyPodcastClassification\")\\\n",
    "    .config('spark.driver.memory', '24g')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29ad7c",
   "metadata": {},
   "source": [
    "# 1. Read full data\n",
    "## 1.1 Podcasts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_df = spark.read.options(inferSchema='True',delimiter=',',header='True') \\\n",
    "                               .csv(\"../script_output/02_final_dat.csv\")\n",
    "podcasts_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e02ebe",
   "metadata": {},
   "source": [
    "105153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_df = podcasts_df.select('episode_uri', 'show_description')\n",
    "podcasts_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3b852",
   "metadata": {},
   "source": [
    "+--------------------+--------------------+\n",
    "|         episode_uri|    show_description|\n",
    "+--------------------+--------------------+\n",
    "|spotify:episode:0...|A 20-something bl...|\n",
    "|spotify:episode:0...|Ever wonder what ...|\n",
    "|spotify:episode:0...|Inside the 18 is ...|\n",
    "|spotify:episode:0...|Your favorite pod...|\n",
    "|spotify:episode:0...|The comedy podcas...|\n",
    "+--------------------+--------------------+\n",
    "only showing top 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ed682",
   "metadata": {},
   "source": [
    "## 1.2 Manually generated topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11683da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = spark.read.options(inferSchema='True', delimiter=',', header='True')\\\n",
    "    .csv('../script_output/topics_manually_created.csv')\n",
    "clusters_kdf = clusters_df.to_koalas()\n",
    "clusters_kdf = clusters_kdf.fillna('')\n",
    "clusters_kdf.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271063be",
   "metadata": {},
   "source": [
    "Comedy\tHealth and fitness\tNews\tPolitics\tPop culture\tReligion\tSports\tTrue crime\n",
    "0\tcomedy\thealth\tnews\tpolitics\tpop culture\treligion\tsports\ttrue crime\n",
    "1\tabsurd\tfitness\ttechnical\targuments\tpop\tsatanism\tNFL\tcold cases\n",
    "2\tfunny\tmental health\tsports news\tjuicy\tcampus\tbible\tfootball\tmystery\n",
    "3\tfunnier\tweight\tweekly news\tpolitical\tadulting\tchristianity\tsoccer\tcrime scene\n",
    "4\teffing\thealthy\tsocial news\tjournalist\thip-hop\treligions\tpremier league\tmurder\n",
    "5\tfuckbois\thealthy weight\tmarket\tinvestigative\tfilm\tfaith\tla liga\tunsolved murders\n",
    "6\tIdiots\tketogenic\tstock\t\ttv shows\tspirituality\tchampions league\tdrama\n",
    "7\tranting\tdiet\tstock market\t\tmusic\tgod\tliga\tvictims\n",
    "8\timprovisers\tbody type\t\t\tmarvel\tconciousness\tleague\tvictim\n",
    "9\tentertain\tintermittent fasting\t\t\tdisney\tthird eye\tboxing\t\n",
    "10\tsatire\tweight loss\t\t\tmovie\t\tfighters\t\n",
    "11\tfunniest\tbody health\t\t\tcontroversial\t\t\t\n",
    "12\t\tskincare\t\t\tlife\t\t\t\n",
    "13\t\tmakeup\t\t\tstories\t\t\t\n",
    "14\t\tbeauty\t\t\tDC\t\t\t\n",
    "15\t\ttreatment\t\t\tmovies\t\t\t\n",
    "16\t\tself-help\t\t\t\t\t\t\n",
    "17\t\tselfcare\t\t\t\t\t\t\n",
    "18\t\tmeditation\t\t\t\t\t\t\n",
    "19\t\tmental health\t\t\t\t\t\t\n",
    "20\t\tbody image\t\t\t\t\t\t\n",
    "21\t\tnutrition\t\t\t\t\t\t\n",
    "22\t\tastrology\t\t\t\t\t\t\n",
    "23\t\tself-development\t\t\t\t\t\t\n",
    "24\t\thealing\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b553a",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / (np.sqrt(np.dot(v2, v2))+.1)\n",
    "\n",
    "def vec_similarity(input1, input2, vectors):\n",
    "    term_vectors = [np.zeros(300), np.zeros(300)]\n",
    "    terms = [input1, input2]\n",
    "        \n",
    "    for index, term in enumerate(terms):\n",
    "        for i, t in enumerate(term.split(' ')):\n",
    "            try:\n",
    "                term_vectors[index] += vectors[t]\n",
    "            except:\n",
    "                term_vectors[index] += 0\n",
    "        \n",
    "    result = (1 - spatial.distance.cosine(term_vectors[0], term_vectors[1]))\n",
    "    if result == 'nan':\n",
    "        result = 0\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vocab_check(vectors, words):\n",
    "    \n",
    "    output = list()\n",
    "    for word in words:\n",
    "        if word in vectors.key_to_index:\n",
    "            output.append(word.strip())\n",
    "            \n",
    "    return output\n",
    "\n",
    "# function calculates similarity between two strings using a particular word vector model\n",
    "def calc_similarity(input1, input2, vectors):\n",
    "    s1words = set(vocab_check(vectors, input1.split()))\n",
    "    s2words = set(vocab_check(vectors, input2.split()))\n",
    "    try: \n",
    "        output = vectors.n_similarity(s1words, s2words)\n",
    "    except: \n",
    "        output = 0\n",
    "    return output\n",
    "\n",
    "def load_wordvec_model(modelName, modelFile, flagBin):\n",
    "    print('Loading ' + modelName + ' model...')\n",
    "    model = KeyedVectors.load_word2vec_format(model_path + modelFile, binary=flagBin)\n",
    "    print('Finished loading ' + modelName + ' model...')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0df191",
   "metadata": {},
   "source": [
    "# 3. Word2Vec with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df23c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ''\n",
    "model_word2vec = load_wordvec_model('Word2Vec', 'GoogleNews-vectors-negative300.bin.gz', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e69287",
   "metadata": {},
   "source": [
    "Loading Word2Vec model...\n",
    "Finished loading Word2Vec model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_pdf=podcasts_df.toPandas()\n",
    "podcasts_pdf = podcasts_pdf[['episode_uri', 'show_description']]\n",
    "podcasts_pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c349050",
   "metadata": {},
   "source": [
    "\tepisode_uri\tshow_description\n",
    "0\tspotify:episode:000A9sRBYdVh66csG2qEdj\tA 20-something blunt female takes on the world...\n",
    "1\tspotify:episode:000HP8n3hNIfglT2wSI2cA\tEver wonder what murder took place on today in...\n",
    "2\tspotify:episode:001UfOruzkA3Bn1SPjcdfa\tInside the 18 is your source for all things Go...\n",
    "3\tspotify:episode:001i89SvIQgDuuyC53hfBm\tYour favorite podcast for everything @Chiefs! ...\n",
    "4\tspotify:episode:0025RWNwe2lnp6HcnfzwzG\tThe comedy podcast about toxic characters, wri...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(clusters_kdf.columns.tolist()): \n",
    "    # Build search query\n",
    "    search_query = ' '.join(clusters_kdf[i].tolist())\n",
    "    podcasts_pdf[i] = podcasts_pdf.apply(lambda row: calc_similarity(search_query, row.show_description, model_word2vec), axis = 1)\n",
    "    \n",
    "    # Status check\n",
    "    print(f\"Completed loop {idx+1}/{len(clusters_kdf.columns.tolist())}...\")\n",
    "podcasts_pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7177a",
   "metadata": {},
   "source": [
    "21/12/13 11:08:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
    "Completed loop 1/8...\n",
    "Completed loop 2/8...\n",
    "Completed loop 3/8...\n",
    "Completed loop 4/8...\n",
    "Completed loop 5/8...\n",
    "Completed loop 6/8...\n",
    "Completed loop 7/8...\n",
    "Completed loop 8/8..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce20b5e",
   "metadata": {},
   "source": [
    "\tepisode_uri\tshow_description\tComedy\tHealth and fitness\tNews\tPolitics\tPop culture\tReligion\tSports\tTrue crime\n",
    "0\tspotify:episode:000A9sRBYdVh66csG2qEdj\tA 20-something blunt female takes on the world...\t0.351232\t0.391297\t0.343048\t0.317570\t0.465362\t0.280541\t0.252791\t0.272252\n",
    "1\tspotify:episode:000HP8n3hNIfglT2wSI2cA\tEver wonder what murder took place on today in...\t0.400637\t0.439645\t0.431746\t0.375465\t0.550336\t0.425099\t0.353148\t0.503461\n",
    "2\tspotify:episode:001UfOruzkA3Bn1SPjcdfa\tInside the 18 is your source for all things Go...\t0.348215\t0.445070\t0.429135\t0.337475\t0.430267\t0.288212\t0.402266\t0.282152\n",
    "3\tspotify:episode:001i89SvIQgDuuyC53hfBm\tYour favorite podcast for everything @Chiefs! ...\t0.351075\t0.390580\t0.510007\t0.297533\t0.481944\t0.290662\t0.261531\t0.226690\n",
    "4\tspotify:episode:0025RWNwe2lnp6HcnfzwzG\tThe comedy podcast about toxic characters, wri...\t0.489705\t0.399399\t0.401080\t0.397278\t0.505520\t0.395204\t0.307015\t0.329007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_pdf['cluster'] = podcasts_pdf.iloc[:, 2:].apply(lambda s: s.nlargest(3).index.tolist(), axis=1)\n",
    "podcasts_pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f9eb4",
   "metadata": {},
   "source": [
    "# 4. Join the Full Metadata for Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('../script_output/episode_transcript_data_w_metadata.csv')\n",
    "full_data = full_data[['show_uri', 'show_name', 'publisher', 'episode_uri', 'episode_name', 'episode_description', 'transcript']]\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.merge(podcasts_pdf, full_data, on='episode_uri', how = 'left')\n",
    "final_result = final_result[['show_name','episode_uri', 'show_description', 'episode_description', 'cluster', \n",
    "                             'True crime', 'Comedy', 'Health and fitness', 'News', 'Politics', 'Pop culture', 'Religion', 'Sports']]\n",
    "manual_annotate_podcasts = final_result.loc[:50,['episode_uri', 'show_description', 'cluster']]\n",
    "manual_annotate_podcasts.to_csv('../script_output/03b_manual_word2vec_manually_annotate.csv', index = False)\n",
    "final_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb781b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv('../script_output/03b_manual_word2vec_final_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
